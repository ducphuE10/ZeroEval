
| Model                          | GSM-Acc | MMLU-Redux |    Avg.     |
|--------------------------------|---------|------------|-------------|
| gpt-4o-2024-05-13              | 95.38   | 88.01      | 91.695      |
| claude-3-5-sonnet-20240620     | 95.6    | 86         | 90.8        |
| gemini-1.5-pro                 | 93.4    | 82.76      | 88.08       |
| gpt-4o-mini-2024-07-18         | 94.24   | 81.5       | 87.87       |
| deepseek-chat-0628             | 93.93   | 80.81      | 87.37       |
| Qwen2-72B-Instruct             | 92.72   | 81.57      | 87.145      |
| deepseek-coder-0628            | 93.78   | 79.63      | 86.705      |
| Meta-Llama-3-70B-Instruct      | 93.03   | 77.97      | 85.5        |
| gemma-2-27b-it@together        | 90.22   | 75.67      | 82.945      |
| Athene-70B                     | 86.66   | 76.53      | 81.595      |
| Yi-1.5-34B-Chat                | 84.38   | 73.04      | 78.71       |
| Mistral-Nemo-Instruct-2407     | 82.79   | 66.88      | 74.835      |
| gpt-3.5-turbo-0125             | 80.36   | 68.36      | 74.36       |
| Qwen2-7B-Instruct              | 80.06   | 66.92      | 73.49       |
| Yi-1.5-9B-Chat                 | 77.86   | 65.05      | 71.455      |
| Meta-Llama-3-8B-Instruct       | 78.47   | 61.66      | 70.065      |


