| Model                       |   GSM8K |   MMLU<br/>-Redux |   ZebraLogic<br/>-Full |   CRUX |   Average |
|:----------------------------|--------:|------------------:|-----------------------:|-------:|----------:|
| gpt-4o-2024-05-13           |   95.38 |             88.01 |                  28.20 |  83.62 |     73.80 |
| claude-3-5-sonnet-20240620  |   95.60 |             86.00 |                  33.40 |  78.75 |     73.44 |
| Llama-3.1-405B-Inst-fp8     |   95.91 |             85.64 |                  32.60 |  72.12 |     71.57 |
| Mistral-Large-2             |   95.53 |             82.97 |                  29.00 |  72.88 |     70.09 |
| gemini-1.5-pro-exp-0801     |   95.00 |             85.53 |                  25.20 |  73.00 |     69.68 |
| claude-3-opus-20240229      |   95.60 |             82.54 |                  27.00 |  68.62 |     68.44 |
| gpt-4o-mini-2024-07-18      |   94.24 |             81.50 |                  20.10 |  73.50 |     67.34 |
| deepseek-v2-chat-0628       |   93.93 |             80.81 |                  22.70 |  68.50 |     66.48 |
| Meta-Llama-3.1-70B-Instruct |   94.16 |             82.97 |                  24.90 |  62.62 |     66.16 |
| deepseek-v2-coder-0724      |   91.51 |             80.24 |                  20.50 |  67.75 |     65.00 |
| Qwen2-72B-Instruct          |   92.65 |             81.61 |                  21.40 |  57.38 |     63.26 |
| gemini-1.5-flash            |   91.36 |             77.36 |                  19.40 |  61.88 |     62.50 |
| claude-3-sonnet-20240229    |   91.51 |             74.87 |                  18.70 |  64.75 |     62.46 |
| Meta-Llama-3-70B-Instruct   |   93.03 |             78.01 |                  16.80 |  57.12 |     61.24 |
| yi-large-preview            |   82.64 |             82.15 |                  18.90 |  58.63 |     60.58 |
| yi-large                    |   80.06 |             81.17 |                  18.80 |  58.38 |     59.60 |
| gemma-2-27b-it              |   90.22 |             75.67 |                  16.30 |  55.88 |     59.52 |
| claude-3-haiku-20240307     |   88.78 |             72.32 |                  14.30 |  53.62 |     57.26 |
| reka-core-20240501          |   87.41 |             76.42 |                  13.00 |  45.00 |     55.46 |
| gemma-2-9b-it               |   87.41 |             72.82 |                  12.80 |  44.88 |     54.48 |
| gpt-3.5-turbo-0125          |   80.36 |             68.36 |                  10.10 |  53.25 |     53.02 |
| Yi-1.5-34B-Chat             |   84.08 |             72.79 |                  11.50 |  42.88 |     52.81 |
| Meta-Llama-3.1-8B-Instruct  |   84.00 |             67.24 |                  12.80 |  38.75 |     50.70 |
| Phi-3-mini-4k-instruct      |   75.51 |             70.34 |                  11.60 |  43.50 |     50.24 |
| Qwen2-7B-Instruct           |   80.06 |             66.92 |                   8.40 |  36.75 |     48.03 |
| Meta-Llama-3-8B-Instruct    |   78.47 |             61.66 |                  11.90 |  36.62 |     47.16 |
| Yi-1.5-9B-Chat              |   76.42 |             65.05 |                   2.30 |  43.75 |     46.88 |
| Mixtral-8x7B-Instruct-v0.1  |   70.13 |             63.17 |                   8.70 |  43.50 |     46.38 |
| reka-flash-20240226         |   74.68 |             64.72 |                   9.30 |  33.25 |     45.49 |
| gemma-2-2b-it               |   51.63 |             51.94 |                   4.20 |  20.75 |     32.13 |