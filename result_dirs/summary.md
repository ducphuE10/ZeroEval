| Model                         |   GSM |   MMLU<br/>-Redux |   ZebraLogic<br/>-Easy |   Average |
|:------------------------------|------:|------------------:|-----------------------:|----------:|
| claude-3-5-sonnet-20240620    | 95.60 |             86.00 |                  87.50 |     89.70 |
| gpt-4o-2024-05-13             | 95.38 |             88.01 |                  77.86 |     87.08 |
| Llama-3.1-405B-Instruct-Turbo | 95.91 |             76.53 |                  87.14 |     86.53 |
| claude-3-opus-20240229        | 95.60 |             82.54 |                  78.21 |     85.45 |
| deepseek-v2-chat-0628         | 93.93 |             80.81 |                  68.57 |     81.10 |
| gpt-4o-mini-2024-07-18        | 94.24 |             81.50 |                  62.50 |     79.41 |
| Qwen2-72B-Instruct            | 92.65 |             81.61 |                  63.93 |     79.40 |
| deepseek-v2-coder-0614        | 93.78 |             79.63 |                  64.64 |     79.35 |
| gemini-1.5-pro                | 93.40 |             82.76 |                  55.71 |     77.29 |
| gemini-1.5-flash              | 91.36 |             77.36 |                  59.29 |     76.00 |
| claude-3-sonnet-20240229      | 91.51 |             74.87 |                  58.93 |     75.10 |
| Meta-Llama-3-70B-Instruct     | 93.03 |             78.01 |                  52.86 |     74.63 |
| yi-large-preview              | 82.64 |             82.15 |                  58.93 |     74.57 |
| yi-large                      | 80.06 |             81.17 |                  58.21 |     73.15 |
| gemma-2-27b-it                | 90.22 |             75.67 |                  50.71 |     72.20 |
| Athene-70B                    | 86.66 |             76.64 |                  52.50 |     71.93 |
| claude-3-haiku-20240307       | 88.78 |             72.32 |                  47.86 |     69.65 |
| reka-core-20240501            | 87.41 |             76.42 |                  43.21 |     69.01 |
| gemma-2-9b-it                 | 87.41 |             72.82 |                  41.79 |     67.34 |
| Yi-1.5-34B-Chat               | 84.08 |             72.79 |                  37.50 |     64.79 |
| command-r-plus                | 80.14 |             68.61 |                  44.64 |     64.46 |
| Mistral-Nemo-Instruct-2407    | 82.79 |             66.88 |                  38.93 |     62.87 |
| Phi-3-mini-4k-instruct        | 75.51 |             70.34 |                  38.21 |     61.35 |
| gpt-3.5-turbo-0125            | 80.36 |             68.36 |                  33.57 |     60.76 |
| Meta-Llama-3-8B-Instruct      | 78.47 |             61.66 |                  40.71 |     60.28 |
| Qwen2-7B-Instruct             | 80.06 |             66.92 |                  29.29 |     58.76 |
| reka-flash-20240226           | 74.68 |             64.72 |                  30.71 |     56.70 |
| Mixtral-8x7B-Instruct-v0.1    | 70.13 |             63.17 |                  28.93 |     54.08 |
| Yi-1.5-9B-Chat                | 76.42 |             65.05 |                   8.21 |     49.89 |
| command-r                     | 52.99 |             61.12 |                  32.14 |     48.75 |